{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3105300f",
   "metadata": {},
   "source": [
    "# Scraping More than 500 Tweets\n",
    "https://towardsdatascience.com/an-extensive-guide-to-collecting-tweets-from-twitter-api-v2-for-academic-research-using-python-3-518fcb71df2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf279184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import dateutil\n",
    "import json\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051cddf3",
   "metadata": {},
   "source": [
    "## Query parameters\n",
    "https://developer.twitter.com/en/docs/twitter-api/tweets/search/api-reference/get-tweets-search-all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0421e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "def create_headers():\n",
    "    # full academic research access\n",
    "    # MUST HAVE YOUR OWN BEARER TOKEN FROM TWITTER'S API\n",
    "    bearer_token = None\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "    return headers\n",
    "\n",
    "def create_url(query, start_date, end_date, max_results = 10):\n",
    "    # full archive access\n",
    "    search_url = \"https://api.twitter.com/2/tweets/search/all\" \n",
    "\n",
    "    # parameters\n",
    "    query_params = {'query': query,\n",
    "                    'start_time': start_date,\n",
    "                    'end_time': end_date,\n",
    "                    'max_results': max_results,\n",
    "                    'expansions': 'author_id,in_reply_to_user_id,geo.place_id',\n",
    "                    'tweet.fields': 'text,geo,created_at,referenced_tweets',\n",
    "                    'user.fields': 'name,username,created_at,verified',\n",
    "                    'place.fields': 'full_name,id,country,country_code,name',\n",
    "                    'next_token': {}}\n",
    "    return (search_url, query_params)\n",
    "\n",
    "\n",
    "def connect_to_endpoint(url, headers, params, next_token = None):\n",
    "    #params object received from create_url function\n",
    "    params['next_token'] = next_token   \n",
    "    response = requests.request(\"GET\", url, headers = headers, params = params)\n",
    "    print(\"Endpoint Response Code: \" + str(response.status_code))\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def append_to_csv(json_response, fileName):\n",
    "    counter = 0\n",
    "\n",
    "    #Open OR create the target CSV file\n",
    "    csvFile = open(fileName, \"a\", newline=\"\", encoding='utf-8')\n",
    "    csvWriter = csv.writer(csvFile)\n",
    "    \n",
    "    # iterate through each tweet\n",
    "    for i in range(len(json_response['data'])):\n",
    "        tweet = json_response['data'][i]\n",
    "        \n",
    "        # Time created\n",
    "        created_at = dateutil.parser.parse(tweet['created_at'])\n",
    "\n",
    "        # Tweet text\n",
    "        text = tweet['text']\n",
    "        \n",
    "        # replied_to\n",
    "        reply = re.findall(\"@(\\w+)\", text)\n",
    "        if reply != []:\n",
    "            replied_to = reply[0]\n",
    "        else:\n",
    "            replied_to = \" \"\n",
    "            \n",
    "        # Userame and verified\n",
    "        username = \" \"\n",
    "        verified = False\n",
    "        for user in json_response['includes']['users']:\n",
    "            if user['id'] == tweet['author_id']:\n",
    "                username = user['username']\n",
    "                verified = user['verified']\n",
    "        \n",
    "        # Location\n",
    "        if ('geo' in tweet):   \n",
    "            geo_id = tweet['geo']['place_id']\n",
    "            for loc in json_response['includes']['places']:\n",
    "                if loc['id'] == geo_id:\n",
    "                    location = loc['name']   \n",
    "        else:\n",
    "            location = \" \"\n",
    "               \n",
    "        # Assemble all data in a list\n",
    "        res = [username, replied_to, location, verified, created_at, text]\n",
    "        \n",
    "        # Append the result to the CSV file\n",
    "        csvWriter.writerow(res)\n",
    "        counter += 1\n",
    "\n",
    "    # When done, close the CSV file\n",
    "    csvFile.close()\n",
    "\n",
    "    # Print the number of tweets for this iteration\n",
    "    print(\"# of Tweets added from this response: \", counter) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31c93e9",
   "metadata": {},
   "source": [
    "### Fill out parameters and query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca37ac92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((russell westbrook) OR westbrick) -is:retweet -has:links lang:en\n"
     ]
    }
   ],
   "source": [
    "# QUERY\n",
    "# For reference: https://developer.twitter.com/en/docs/twitter-api/tweets/search/integrate/build-a-query\n",
    "with open(\"network_query.txt\", 'r') as fr:\n",
    "    query = fr.read()\n",
    "\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49cb713",
   "metadata": {},
   "source": [
    "# Requesting more than 500 tweets\n",
    "**Time Intervals**\n",
    "- 1 week periods starting at start_interval for the specified n_weeks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02773a1c",
   "metadata": {},
   "source": [
    "**2018-19**\n",
    "start_interval = datetime(2018, 10, 16)\n",
    "end_interval = datetime(2018, 10, 22, 23, 59, 59)\n",
    "n_weeks = 28\n",
    "max_results = 75\n",
    "max_count = 70\n",
    "\n",
    "**2019-20**\n",
    "start_interval = datetime(2019, 10, 22)\n",
    "end_interval = datetime(2019, 10, 28, 23, 59, 59)\n",
    "n_weeks = 40\n",
    "max_results = 50\n",
    "max_count = 45\n",
    "\n",
    "**2020-21**\n",
    "start_interval = datetime(2020, 10, 22)\n",
    "end_interval = datetime(2020, 10, 28, 23, 59, 59)\n",
    "n_weeks = 30\n",
    "max_results = 65\n",
    "max_count = 55\n",
    "\n",
    "**2021-22**\n",
    "start_interval = datetime(2021, 10, 19)\n",
    "end_interval = datetime(2021, 10, 25, 23, 59, 59)\n",
    "n_weeks = 26\n",
    "max_results = 78\n",
    "max_count = 68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0775487e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "# specify start and end dates for intervals (1 week)\n",
    "start_interval = datetime(2021, 10, 19)\n",
    "end_interval = datetime(2021, 10, 25, 23, 59, 59)\n",
    "\n",
    "# how many weeks from start_interval to request\n",
    "n_weeks = 26\n",
    "\n",
    "# store list of tuples in iso format for start and end dates for each week (i.e. [(2020-1-1, 2020-1-7)])\n",
    "request_dates = []\n",
    "for i in range(n_weeks):\n",
    "    start = start_interval + timedelta(weeks=i)\n",
    "    end = end_interval + timedelta(weeks=i)\n",
    "    request_dates.append((start.isoformat()+\"Z\", end.isoformat()+\"Z\"))\n",
    "\n",
    "request_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "122af598",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fpdv6n01mnti3r1sc9c2j0tus9g48t\n",
      "Start Date:  10/19/2021\n",
      "# of Tweets added from this response:  74\n",
      "Total # of Tweets added:  74\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fpdv7w68eykidrrcfglw33aix7bbel\n",
      "Start Date:  10/26/2021\n",
      "# of Tweets added from this response:  69\n",
      "Total # of Tweets added:  143\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fpdv8qu8d3sqhvgo4vrw1bg78fjxx9\n",
      "Start Date:  11/02/2021\n",
      "# of Tweets added from this response:  70\n",
      "Total # of Tweets added:  213\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fpdy5kcbqalna6ojkrm7t9x4pbkrjx\n",
      "Start Date:  11/09/2021\n",
      "# of Tweets added from this response:  72\n",
      "Total # of Tweets added:  285\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fpdy6ey9n3px8xuqb2u4p35rw3qikd\n",
      "Start Date:  11/16/2021\n",
      "# of Tweets added from this response:  71\n",
      "Total # of Tweets added:  356\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fpdy7o4g57ahoyjfzngqoqpi6ieyyl\n",
      "Start Date:  11/23/2021\n",
      "# of Tweets added from this response:  69\n",
      "Total # of Tweets added:  425\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fpdy8iqbnfydii6lqnq6gnri99gprx\n",
      "Start Date:  11/30/2021\n",
      "# of Tweets added from this response:  71\n",
      "Total # of Tweets added:  496\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fpe15cak1y4iqix5prd75yui6an33x\n",
      "Start Date:  12/07/2021\n",
      "# of Tweets added from this response:  68\n",
      "Total # of Tweets added:  564\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fpe166wfkhdhnl6z23do9527jemv0d\n",
      "Start Date:  12/14/2021\n",
      "# of Tweets added from this response:  72\n",
      "Total # of Tweets added:  636\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fpe17g6ste2i23gwuvov2rjbhlouil\n",
      "Start Date:  12/21/2021\n",
      "# of Tweets added from this response:  73\n",
      "Total # of Tweets added:  709\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fpe18pczbem90fyp7to9avy5utqkql\n",
      "Start Date:  12/28/2021\n",
      "# of Tweets added from this response:  75\n",
      "Total # of Tweets added:  784\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fpe454atsrn8cvkjd2q74bozkiw5ml\n",
      "Start Date:  01/04/2022\n",
      "# of Tweets added from this response:  69\n",
      "Total # of Tweets added:  853\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fpe46dh16tb9x7ejk1w7h3dh3i3ptp\n",
      "Start Date:  01/11/2022\n",
      "# of Tweets added from this response:  74\n",
      "Total # of Tweets added:  927\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fpe4784yqk318s5hwkgb8iqbezmiyl\n",
      "Start Date:  01/18/2022\n",
      "# of Tweets added from this response:  73\n",
      "Total # of Tweets added:  1000\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fpe48hb5j3xs8g7f1wavq76yz68znh\n",
      "Start Date:  01/25/2022\n",
      "# of Tweets added from this response:  72\n",
      "Total # of Tweets added:  1072\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fpe74wb38vso6kivilp9dgonayjmgt\n",
      "Start Date:  02/01/2022\n",
      "# of Tweets added from this response:  72\n",
      "Total # of Tweets added:  1144\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fpe765h9fxt9s9crhidxu9x5nb8fi5\n",
      "Start Date:  02/08/2022\n",
      "# of Tweets added from this response:  68\n",
      "Total # of Tweets added:  1212\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fpe77036rf7tbkxfzdg8471p8tz531\n",
      "Start Date:  02/15/2022\n",
      "# of Tweets added from this response:  71\n",
      "Total # of Tweets added:  1283\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fpe789bfvlcx13woujlz2pwaxjixdp\n",
      "Start Date:  02/22/2022\n",
      "# of Tweets added from this response:  75\n",
      "Total # of Tweets added:  1358\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fpyql95gmejdgpcyrx2ay1k32cbhj1\n",
      "Start Date:  03/01/2022\n",
      "# of Tweets added from this response:  75\n",
      "Total # of Tweets added:  1433\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fpyqmibo0sdgreylftx4aih72f9jzx\n",
      "Start Date:  03/08/2022\n",
      "# of Tweets added from this response:  75\n",
      "Total # of Tweets added:  1508\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fpyqnrjxg33kd6rdrqa54196vzf1bx\n",
      "Start Date:  03/15/2022\n",
      "# of Tweets added from this response:  75\n",
      "Total # of Tweets added:  1583\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fpyqom5rrf5ov11zwcahm9m6gk6bgd\n",
      "Start Date:  03/22/2022\n",
      "# of Tweets added from this response:  74\n",
      "Total # of Tweets added:  1657\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fpytlfnxtuahov8eohxoeqmz4cadtp\n",
      "Start Date:  03/29/2022\n",
      "# of Tweets added from this response:  76\n",
      "Total # of Tweets added:  1733\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fpytmabxgwiwixouevnq36mujt7lh9\n",
      "Start Date:  04/05/2022\n",
      "# of Tweets added from this response:  77\n",
      "Total # of Tweets added:  1810\n",
      "-------------------\n",
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fpytnji32i8tytk2agne1nxi5f09rx\n",
      "Start Date:  04/12/2022\n",
      "# of Tweets added from this response:  75\n",
      "Total # of Tweets added:  1885\n",
      "-------------------\n",
      "Total number of results:  1885\n",
      "COMPLETE\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import csv\n",
    "import dateutil\n",
    "import os\n",
    "\n",
    "# set max results per period (up to 500)\n",
    "# calculate n_weeks*max_results is roungly = max total # tweets \n",
    "max_results = 77\n",
    "\n",
    "#Total number of tweets we collected from the loop\n",
    "total_tweets = 0\n",
    "\n",
    "# Create file\n",
    "filename = '2021_22 network tweets.csv'\n",
    "\n",
    "# delete old file\n",
    "try:\n",
    "    os.remove(filename)\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "csvFile = open(filename, \"a\", newline=\"\", encoding='utf-8')\n",
    "csvWriter = csv.writer(csvFile)\n",
    "\n",
    "# Create headers for the data you want to save\n",
    "fields = ['username', 'replied_to_username', 'location', 'verified', 'created_at', 'text']\n",
    "\n",
    "csvWriter.writerow(fields)\n",
    "csvFile.close()\n",
    "\n",
    "headers = create_headers()\n",
    "\n",
    "for i in range(len(request_dates)):\n",
    "    count = 0\n",
    "    # max_count should be ~5 less than max_results\n",
    "    max_count = 68\n",
    "    flag = True\n",
    "    next_token = None\n",
    "    \n",
    "    # Check if flag is true\n",
    "    while flag:\n",
    "        if count >= max_count:\n",
    "            break\n",
    "        print(\"-------------------\")\n",
    "        print(\"Token: \", next_token)\n",
    "        url = create_url(query, request_dates[i][0],request_dates[i][1], max_results)\n",
    "        json_response = connect_to_endpoint(url[0], headers, url[1], next_token)\n",
    "        result_count = json_response['meta']['result_count']\n",
    "\n",
    "        if 'next_token' in json_response['meta']:\n",
    "            # Save the token to use for next call\n",
    "            next_token = json_response['meta']['next_token']\n",
    "            print(\"Next Token: \", next_token)\n",
    "            if result_count is not None and result_count > 0 and next_token is not None:\n",
    "                print(\"Start Date: \", datetime.fromisoformat(request_dates[i][0][:-1]).strftime(\"%m/%d/%Y\"))\n",
    "                append_to_csv(json_response, filename)\n",
    "                count += result_count\n",
    "                total_tweets += result_count\n",
    "                print(\"Total # of Tweets added: \", total_tweets)\n",
    "                print(\"-------------------\")\n",
    "                time.sleep(1)                \n",
    "        # If no next token exists\n",
    "        else:\n",
    "            if result_count is not None and result_count > 0:\n",
    "                print(\"-------------------\")\n",
    "                print(\"Start Date: \", datetime.fromisoformat(request_dates[i][0][:-1]).strftime(\"%m/%d/%Y\"))\n",
    "                append_to_csv(json_response, filename)\n",
    "                count += result_count\n",
    "                total_tweets += result_count\n",
    "                print(\"Total # of Tweets added: \", total_tweets)\n",
    "                print(\"-------------------\")\n",
    "                time.sleep(1)\n",
    "            \n",
    "            #Since this is the final request, turn flag to false to move to the next time period.\n",
    "            flag = False\n",
    "            next_token = None\n",
    "        time.sleep(1)\n",
    "print(\"Total number of results: \", total_tweets)\n",
    "print(\"COMPLETE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aac51eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read data\n",
    "filename = '2016_17 network tweets.csv'\n",
    "\n",
    "df = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eeb3597c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>replied_to_username</th>\n",
       "      <th>location</th>\n",
       "      <th>verified</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>athegreat584</td>\n",
       "      <td>NBA</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>2016-10-31 23:59:50+00:00</td>\n",
       "      <td>@NBA \\nRussell Westbrook is simply a machine; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rxjjy96</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>2016-10-31 23:56:44+00:00</td>\n",
       "      <td>If Russell Westbrook don't get MVP this season...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>duvaljr</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>2016-10-31 23:55:25+00:00</td>\n",
       "      <td>Nothing about Russell Westbrook game changed. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>prince_nueve</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>2016-10-31 23:53:09+00:00</td>\n",
       "      <td>Russell Westbrook and Damian Lillard are ballers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MontezzAllen313</td>\n",
       "      <td></td>\n",
       "      <td>Chicago</td>\n",
       "      <td>False</td>\n",
       "      <td>2016-10-31 23:43:38+00:00</td>\n",
       "      <td>Will Russell Westbrook win MVP this season?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username replied_to_username location  verified  \\\n",
       "0     athegreat584                 NBA              False   \n",
       "1          rxjjy96                                  False   \n",
       "2          duvaljr                                  False   \n",
       "3     prince_nueve                                  False   \n",
       "4  MontezzAllen313                      Chicago     False   \n",
       "\n",
       "                  created_at  \\\n",
       "0  2016-10-31 23:59:50+00:00   \n",
       "1  2016-10-31 23:56:44+00:00   \n",
       "2  2016-10-31 23:55:25+00:00   \n",
       "3  2016-10-31 23:53:09+00:00   \n",
       "4  2016-10-31 23:43:38+00:00   \n",
       "\n",
       "                                                text  \n",
       "0  @NBA \\nRussell Westbrook is simply a machine; ...  \n",
       "1  If Russell Westbrook don't get MVP this season...  \n",
       "2  Nothing about Russell Westbrook game changed. ...  \n",
       "3   Russell Westbrook and Damian Lillard are ballers  \n",
       "4        Will Russell Westbrook win MVP this season?  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e240bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
